---
title: About
layout: page
---
![Profile Image]({% if site.external-image %}{{ site.picture }}{% else %}{{ site.url }}/{{ site.picture }}{% endif %})

<p>
  Akshay K. Jagadish is a postdoctoral research fellow at the <a href="https://ai.princeton.edu/ai-lab/people/postdocs-and-scholars">Princeton AI Lab</a>. His work bridges cognitive science and artificial intelligence, taking two complementary approaches to understanding natural and artificial minds:
</p>
<ol style="margin-top: -19px;">
  <li>Designing scalable, sub-symbolic models of human and machine cognition through frameworks such as <a href="https://arxiv.org/abs/2304.06729">meta-learning</a>, <a href="https://arxiv.org/abs/2402.03969">rational analysis</a>, <a href="https://arxiv.org/abs/2402.01821">ecological rationality</a>, <a href="https://osf.io/preprints/psyarxiv/ymve5">resource-rationality</a> and <a href="https://escholarship.org/uc/item/7k85s0j0">bounded ecologically rational analysis</a>.</li>
  <li>Developing AI-driven methods to uncover interpretable <a href="https://arxiv.org/pdf/2502.00879.pdf">symbolic programs of behavior</a> and the internal representations that guide them.</li>
</ol>
<p>
  Before joining Princeton, he spent six wonderful years in Germany, where he earned a Ph.D. in Computer Science and an M.Sc. in Computational Neuroscience at the University of Tübingen under the mentorship of Eric Schulz and Marcel Binz. His research has been featured in popular press, including The New York Times<sup>[<a href="http://www.nytimes.com/2025/03/17/science/chatgpt-digital-therapists-anxiety.html">1</a>][<a href="https://www.nytimes.com/2025/07/02/science/ai-psychology-mind.html">2</a>]</sup>, Fortune<sup>[<a href="https://fortune.com/2025/03/09/openai-chatgpt-anxiety-mindfulness-mental-health-intervention/?abc123">3</a>]</sup>, Tagesspiegel<sup>[<a href="https://www.tagesspiegel.de/wissen/wie-denkt-chatgpt-geht-ein-chatbot-zum-psychologen-11726375.html">4</a>]</sup>, and Science Daily<sup>[<a href="https://www.sciencedaily.com/releases/2025/03/250303141645.htm">5</a>]</sup>.
</p>

<h2>Key Publications</h2>

<p>
Binz, M., Dasgupta, I., <b>Jagadish, A. K.</b>, Botvinick, M., Wang, J.X., & Schulz, E. (2024). 
<a href="https://arxiv.org/abs/2304.06729/">Meta-Learned Models of Cognition</a>. Behavioral and Brain Sciences. 
<span style="vertical-align:-75%"></span><br>

<b>Jagadish, A. K.</b>, Coda-Forno, J., Thalmann, M., Schulz, E., & Binz, M. (2024). 
<a href="https://arxiv.org/abs/2402.01821">Human-like Category Learning by Injecting Ecological Priors from Large Language Models into Neural Networks</a>. 
Proceedings of the 41st International Conference on Machine Learning (ICML), Vienna, Austria. 
<span style="vertical-align:-75%"></span><br>

Schubert, J. A., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (2024). 
<a href="https://arxiv.org/abs/2402.03969">In-Context Learning Agents Are Asymmetric Belief Updaters</a>. 
Proceedings of the 41st International Conference on Machine Learning (ICML), Vienna, Austria. 
<span style="vertical-align:-75%"></span><br>

Rmus, M.*, <b>Jagadish, A. K.</b>*, Mathony, M., & Schulz, E. (2025). 
<a href="https://arxiv.org/pdf/2502.00879.pdf">Generating Computational Cognitive Models using Large Language Models</a>. 
Advances in Neural Information Processing Systems (NeurIPS), San Diego, USA. 
<span style="vertical-align:-75%"></span><br>

<b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (2025). 
<a href="">Meta-learning Ecological Priors from Large Language Models explains Human Learning and Decision making</a>. 
Under review. 
<span style="vertical-align:-75%"></span><br>
</p>


<!-- Coda-Forno, J., Witte, K., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (under review). <a href="https://arxiv.org/abs/2304.11111">Inducing anxiety in large language models increases exploration and bias</a>. <span style="vertical-align:-75%"></span><br> -->
<!-- <li><a href="https://osf.io/preprints/psyarxiv/j7fwb">“Chat-GPT on the Couch”: Mitigating State Anxiety in Large Language Models via Mindfulness-based Relaxation Techniques</a></li> 
-->
<!-- <b>Jagadish, A. K.</b>, Binz, M., Saanum, T., Wang, J.X., & Schulz, E. (under review). <a href="https://osf.io/preprints/psyarxiv/ymve5">Zero-shot compositional reasoning in a reinforcement learning setting</a>.<span style="vertical-align:-75%"></span> <br> -->
<!-- Coda-Forno, J., Witte, K., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (under review). <a href="https://arxiv.org/abs/2304.11111">Inducing anxiety in large language models increases exploration and bias</a>. <span style="vertical-align:-75%"></span><br> -->
