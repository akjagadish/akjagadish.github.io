---
title: About
layout: page
---
![Profile Image]({% if site.external-image %}{{ site.picture }}{% else %}{{ site.url }}/{{ site.picture }}{% endif %})

<p>
  Akshay K. Jagadish is a postdoctoral research fellow at the Princeton AI Lab. His work focuses on:
</p>
<ol style="margin-top: -29px;">
  <li>Uncovering the essential ingredients of human cognition by building scalable models of human cognitive function. </li>
  <li>Developing AI-driven methods to accelerate the discovery of interpretable models of human behavior and their internal representations.</li>
</ol>

<h2>Key Publications</h2>

<p>
Binz, M., Dasgupta, I., <b>Jagadish, A. K.</b>, Botvinick, M., Wang, J.X., & Schulz, E. (2024). 
<a href="https://arxiv.org/abs/2304.06729/">Meta-Learned Models of Cognition</a>. Behavioral and Brain Sciences. 
<span style="vertical-align:-75%"></span><br>

<b>Jagadish, A. K.</b>, Coda-Forno, J., Thalmann, M., Schulz, E., & Binz, M. (2024). 
<a href="https://arxiv.org/abs/2402.01821">Human-like Category Learning by Injecting Ecological Priors from Large Language Models into Neural Networks</a>. 
Proceedings of the 41st International Conference on Machine Learning (ICML), Vienna, Austria. 
<span style="vertical-align:-75%"></span><br>

Schubert, J. A., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (2024). 
<a href="https://arxiv.org/abs/2402.03969">In-Context Learning Agents Are Asymmetric Belief Updaters</a>. 
Proceedings of the 41st International Conference on Machine Learning (ICML), Vienna, Austria. 
<span style="vertical-align:-75%"></span><br>

Rmus, M.*, <b>Jagadish, A. K.</b>*, Mathony, M., & Schulz, E. (2025). 
<a href="https://arxiv.org/pdf/2502.00879.pdf">Generating Computational Cognitive Models using Large Language Models</a>. 
Under review. 
<span style="vertical-align:-75%"></span><br>

<b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (2025). 
<a href="">Meta-learning Ecological Priors from Large Language Models explains Human Learning and Decision making</a>. 
Under review. 
<span style="vertical-align:-75%"></span><br>
</p>


<!-- Coda-Forno, J., Witte, K., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (under review). <a href="https://arxiv.org/abs/2304.11111">Inducing anxiety in large language models increases exploration and bias</a>. <span style="vertical-align:-75%"></span><br> -->
<!-- <li><a href="https://osf.io/preprints/psyarxiv/j7fwb">“Chat-GPT on the Couch”: Mitigating State Anxiety in Large Language Models via Mindfulness-based Relaxation Techniques</a></li> 
-->
<!-- <b>Jagadish, A. K.</b>, Binz, M., Saanum, T., Wang, J.X., & Schulz, E. (under review). <a href="https://osf.io/preprints/psyarxiv/ymve5">Zero-shot compositional reasoning in a reinforcement learning setting</a>.<span style="vertical-align:-75%"></span> <br> -->
<!-- Coda-Forno, J., Witte, K., <b>Jagadish, A. K.</b>, Binz, M., & Schulz, E. (under review). <a href="https://arxiv.org/abs/2304.11111">Inducing anxiety in large language models increases exploration and bias</a>. <span style="vertical-align:-75%"></span><br> -->
